<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.8.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"caixiaobai.github.io","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="MapReduce是什么MapReduce是一种分布式计算编程框架，是Hadoop主要组成部分之一，可以让用户专注于编写核心逻辑代码，最后以高可靠、高容错的方式在大型集群上并行处理大量数据。 MapReduce的存储MapReduce的数据是存储在HDFS上的，HDFS也是Hadoop的主要组成部分之一。下边是MapReduce在HDFS上的存储的图解  HDFS主要有Namenode和Datan">
<meta name="keywords" content="大数据,MapReduce">
<meta property="og:type" content="article">
<meta property="og:title" content="学习笔记—MapReduce">
<meta property="og:url" content="https://caixiaobai.github.io/2018/12/07/学习笔记—MapReduce/index.html">
<meta property="og:site_name" content="KeepUp&#39;s Blog">
<meta property="og:description" content="MapReduce是什么MapReduce是一种分布式计算编程框架，是Hadoop主要组成部分之一，可以让用户专注于编写核心逻辑代码，最后以高可靠、高容错的方式在大型集群上并行处理大量数据。 MapReduce的存储MapReduce的数据是存储在HDFS上的，HDFS也是Hadoop的主要组成部分之一。下边是MapReduce在HDFS上的存储的图解  HDFS主要有Namenode和Datan">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNbRwly1fxw93ewkoej31720g4tfx.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwly1fxyltiwrcdj31gg0nw1kx.jpg">
<meta property="og:image" content="http://hadoop.apache.org/docs/r3.1.1/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwly1fxr3rttfbgj308c08b3zp.jpg">
<meta property="og:updated_time" content="2018-12-07T15:55:03.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="学习笔记—MapReduce">
<meta name="twitter:description" content="MapReduce是什么MapReduce是一种分布式计算编程框架，是Hadoop主要组成部分之一，可以让用户专注于编写核心逻辑代码，最后以高可靠、高容错的方式在大型集群上并行处理大量数据。 MapReduce的存储MapReduce的数据是存储在HDFS上的，HDFS也是Hadoop的主要组成部分之一。下边是MapReduce在HDFS上的存储的图解  HDFS主要有Namenode和Datan">
<meta name="twitter:image" content="http://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png">

<link rel="canonical" href="https://caixiaobai.github.io/2018/12/07/学习笔记—MapReduce/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'default'
  };
</script>

  <title>学习笔记—MapReduce | KeepUp's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">KeepUp's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope="" itemtype="http://schema.org/Article" class="post-block" lang="default">
    <link itemprop="mainEntityOfPage" href="https://caixiaobai.github.io/2018/12/07/学习笔记—MapReduce/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="KeepUp">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KeepUp's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          学习笔记—MapReduce
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2018-12-07 23:27:12 / Modified: 23:55:03" itemprop="dateCreated datePublished" datetime="2018-12-07T23:27:12+08:00">2018-12-07</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据学习/" itemprop="url" rel="index"><span itemprop="name">大数据学习</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h4 id="MapReduce是什么"><a href="#MapReduce是什么" class="headerlink" title="MapReduce是什么"></a>MapReduce是什么</h4><p>MapReduce是一种分布式计算编程框架，是Hadoop主要组成部分之一，可以让用户专注于编写核心逻辑代码，最后以高可靠、高容错的方式在大型集群上并行处理大量数据。</p>
<h4 id="MapReduce的存储"><a href="#MapReduce的存储" class="headerlink" title="MapReduce的存储"></a>MapReduce的存储</h4><p>MapReduce的数据是存储在HDFS上的，HDFS也是Hadoop的主要组成部分之一。下边是MapReduce在HDFS上的存储的图解</p>
<p><img src="http://hadoop.apache.org/docs/r3.1.1/hadoop-project-dist/hadoop-hdfs/images/hdfsarchitecture.png" alt="HDFS Architecture"></p>
<p>HDFS主要有Namenode和Datanode两部分组成，整个集群有一个Namenode和多个DataNode，通常每一个节点一个DataNode，Namenode的主要功能是用来管理客户端client对数据文件的操作请求和储存数据文件的地址。DataNode主要是用来储存和管理本节点的数据文件。节点内部数据文件被分为一个或多个block块（block默认大小原来是64MB，后来变为128MB），然后这些块储存在一组DataNode中。（这里不对HDFS做过多的介绍，后续会写一篇详细的HDFS笔记）</p>
<h4 id="MapReduce的运行流程"><a href="#MapReduce的运行流程" class="headerlink" title="MapReduce的运行流程"></a>MapReduce的运行流程</h4><p><img src="https://ws2.sinaimg.cn/large/006tNbRwly1fxw93ewkoej31720g4tfx.jpg" alt="屏幕快照 2018-12-05 下午10.43.38"></p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwly1fxyltiwrcdj31gg0nw1kx.jpg" alt="屏幕快照 2018-12-05 下午10.56.38"></p>
<p>1、首先把需要处理的数据文件上传到HDFS上，然后这些数据会被分为好多个小的分片，然后每个分片对应一个map任务，推荐情况下分片的大小等于block块的大小。然后map的计算结果会暂存到一个内存缓冲区内，该缓冲区默认为100M，等缓存的数据达到一个阈值的时候，默认情况下是80%，然后会在磁盘创建一个文件，开始向文件里边写入数据。</p>
<p>2、map任务的输入数据的格式是<key,value>对的形式，我们也可以自定义自己的<key,value>类型。然后map在往内存缓冲区里写入数据的时候会根据key进行排序，同样溢写到磁盘的文件里的数据也是排好序的，最后map任务结束的时候可能会产生多个数据文件，然后把这些数据文件再根据归并排序合并成一个大的文件。</key,value></key,value></p>
<p>3、然后每个分片都会经过map任务后产生一个排好序的文件，同样文件的格式也是<key,value>对的形式，然后通过对key进行hash的方式把数据分配到不同的reduce里边去，这样对每个分片的数据进行hash，再把每个分片分配过来的数据进行合并，合并过程中也是不断进行排序的。最后数据经过reduce任务的处理就产生了最后的输出。</key,value></p>
<p>4、在我们开发中只需要对中间map和reduce的逻辑进行开发就可以了，中间分片，排序，合并，分配都有MapReduce框架帮我完成了。</p>
<h4 id="MapReduce的资源调度系统"><a href="#MapReduce的资源调度系统" class="headerlink" title="MapReduce的资源调度系统"></a>MapReduce的资源调度系统</h4><p>最后我们来看一下MapReduce的资源调度系统Yarn。</p>
<p><img src="http://hadoop.apache.org/docs/r3.1.1/hadoop-yarn/hadoop-yarn-site/yarn_architecture.gif" alt="MapReduce NextGenæ¶æ"></p>
<p>Yarn的基本思想是将资源管理和作业调度/监视的功能分解为单独的守护进程。全局唯一的ResourceManager是负责所有应用程序之间的资源的调度和分配，每个程序有一个ApplicationMaster，ApplicationMaster实际上是一个特定于框架的库，其任务是协调来自ResourceManager的资源，并与NodeManager一起执行和监视任务。NodeManager是每台机器框架代理，监视其资源使用情况（CPU，内存，磁盘，网络）并将其报告给ResourceManager。</p>
<h4 id="WordConut代码"><a href="#WordConut代码" class="headerlink" title="WordConut代码"></a>WordConut代码</h4><ul>
<li>python实现</li>
</ul>
<p>map.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    words = line.strip().split()</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        print(<span class="string">'%s\t%s'</span> % (word, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>reduce.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:UTF-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">current_word = <span class="keyword">None</span></span><br><span class="line">sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    word, count = line.strip().split(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> current_word == <span class="keyword">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> word != current_word:</span><br><span class="line">        print(<span class="string">'%s\t%s'</span> % (current_word, sum))</span><br><span class="line">        current_word = word</span><br><span class="line">        sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    sum += int(count)</span><br><span class="line"></span><br><span class="line">print(<span class="string">'%s\t%s'</span> % (current_word, sum))</span><br></pre></td></tr></table></figure>
<p>我们先把输入文件上传到HDFS上去</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /input.txt /</span><br></pre></td></tr></table></figure>
<p>​    然后在Linux下运行，为了方便我们把命令写成了shell文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_CMD="/usr/local/src/hadoop-2.6.1/bin/hadoop"</span><br><span class="line">STREAM_JAR_PATH="/usr/local/src/hadoop-2.6.1/share/hadoop/tools/lib/hadoop-streaming-2.6.1.jar"</span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH="/input.txt"</span><br><span class="line">OUTPUT_FILE_PATH="/output"</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span>HADOOP_CMD fs -rmr -skipTrush $OUTPUT_FILE_PATH</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span>HADOOP_CMD jar $STREAM_JAR_PATH \</span><br><span class="line">	-input $INPUT_FILE_PATH \</span><br><span class="line">	-output $OUTPUT_FILE_PATH \</span><br><span class="line">	-mapper "python map.py" \</span><br><span class="line">	-reducer "python reduce.py" \</span><br><span class="line">	-file "./map.py" \</span><br><span class="line">	-file "./reduce.py"</span><br></pre></td></tr></table></figure>
<ul>
<li>java实现</li>
</ul>
<p>MyMap.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMap</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> Text text = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        String line = value.toString();</span><br><span class="line">        String[] words = line.split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (String word: words)&#123;</span><br><span class="line">            text.set(word);</span><br><span class="line">            context.write(text,one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MyReduce.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReduce</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable i:values)&#123;</span><br><span class="line">            sum+=i.get();</span><br><span class="line">        &#125;</span><br><span class="line">        result.set(sum);</span><br><span class="line">        context.write(key,result);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>WordCount.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Configuration configuration = <span class="keyword">new</span> Configuration();</span><br><span class="line">        Job job = Job.getInstance(configuration, <span class="string">"WordCount"</span>);</span><br><span class="line">        job.setJarByClass(WordCount.class);</span><br><span class="line">        job.setMapperClass(MyMap.class);</span><br><span class="line">        job.setReducerClass(MyReduce.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把工程打成jar包，然后把jar包和输入文件上传到HDfs</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> hadoop fs -put /wordcount.jar /</span><br><span class="line"><span class="meta">$</span> hadoop fs -put /input.txt /</span><br></pre></td></tr></table></figure>
<p>执行wordcount任务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> bin/hadoop jar wordcount.jar WordCount /input.txt /user/joe/wordcount/output</span><br></pre></td></tr></table></figure>
<hr>
<p>欢迎关注公众号：「努力给自己看」</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwly1fxr3rttfbgj308c08b3zp.jpg" alt="扫码"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/大数据/" rel="tag"># 大数据</a>
              <a href="/tags/MapReduce/" rel="tag"># MapReduce</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2018/12/01/hexo博客更换主题/" rel="prev" title="hexo博客更换主题">
      <i class="fa fa-chevron-left"></i> hexo博客更换主题
    </a></div>
      <div class="post-nav-item">
    <a href="/2018/12/09/TF-IDF介绍/" rel="next" title="TF-IDF介绍">
      TF-IDF介绍 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce是什么"><span class="nav-number">1.</span> <span class="nav-text">MapReduce是什么</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce的存储"><span class="nav-number">2.</span> <span class="nav-text">MapReduce的存储</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce的运行流程"><span class="nav-number">3.</span> <span class="nav-text">MapReduce的运行流程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#MapReduce的资源调度系统"><span class="nav-number">4.</span> <span class="nav-text">MapReduce的资源调度系统</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#WordConut代码"><span class="nav-number">5.</span> <span class="nav-text">WordConut代码</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">KeepUp</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">37</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">KeepUp</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  















  

  

</body>
</html>
